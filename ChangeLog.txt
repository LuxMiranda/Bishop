V 1.1.3
=======
	- Big bug fix in incomplete path inferences.
	- Big bug fix in Planner.Likelihood().
	- PosteriorContainer has new method, SaveCSV, that exports everything to an R-friendly .csv file
	- Expanded AgentSimulation class.
	- Optimized Planner.Likelihood() a bit.
	- Deleted all .egg files from buggy builds (All versions between 2.1.0 and 2.0.0).
	- Other small bug fixes.

V 1.1.2
=======
	- New class for saving agent simulations (AgentSimulation)
	- Support for model testing by correlating generative model input with inferences (Observer.TestModel).
	- Improved progress bars.
	- Observer.InferAgent() now accepts numeric or string action sequences.
	- Bug fixes.

V 1.1.1
=======
	- Internal restructuring changes.
	- Bug fixes.

V 1.1.0
=======
	- Added support for inference over incomplete paths.

V 2.0.0
=======
	- Bishop now has a concept of a goal. Rather than planning through a massive MDP it now generates sub-MDPs and does goal-selection through a utility function.
	- Lost support for inference over incomplete paths.

V 2.2.0
=======
	- Cost and reward functions can now be set to constant
	- Probability mass centered on 0 can now be set separately for the cost and the reward function (Apathy -> CNull and RNull).
	- New support for empirically set priors.
	- Maps can now be stored in subfolders.
	- Summary functions add sample with highest likelihood.

V 2.2.1
=======
	- Fixed some naming schemes. LoadMap() is now LoadObserver().
	- AgentSimulation can now also save output into CSV files.

V 2.3.0
=======
	- Fixed a big bug. Code assumed that the CostMatrix was symmetric and this is not necessarily true.

V 2.4.0
=======
	- Modified ValueIteration and Policy builder on MDP. Replacing target state on subMDPs for a big reward biased the agent to push diagonal actions to the end (because that way you save square root of 2 cost).

V 2.5.0
=======
	- Agents now have a minimum number of objects to collect and a capacity.
	- Updated examples and documentation.
	- More priors.
