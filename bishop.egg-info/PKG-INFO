Metadata-Version: 1.0
Name: Bishop
Version: 2.4.0
Summary: Cognitive model of Theory of Mind
Home-page: http://gibthub.com/julianje/bishop
Author: Julian Jara-Ettinger
Author-email: jjara@mit.edu
License: MIT
Description: #Bishop
        ______
        
        ## About
        
        Bishop, after [Washington Bishop](http://en.wikipedia.org/wiki/Washington_Irving_Bishop), is a python package for modeling  [Theory of mind](http://en.wikipedia.org/wiki/Theory_of_mind). Given some observable behavior, Bishop infers (through Bayesian inference over a rational model of decision making and planning under uncertainty) the cost and reward functions that explain the agent's choices and actions.
        
        ## Install and uninstall
        
        	python setup.py install
        	pip uninstall Bishop
        
        ## Using Bishop
        
        Simulate agents:
        
        	from Bishop import *	
        	Observer = LoadObserver("FlagSetup")
        	R = Observer.SimulateAgents(Samples=100) # Generate 100 random agents.
        	R.SaveCSV("MySamples.csv") # Save costs, rewards, actions, and state transitions as a CSV file.
        	R.Display() # Print everything
        
        To see a list of available maps:
        	
        	ShowAvailableMaps()
        
        #### Cost-reward inference given observable actions
        
        #### From the terminal
        
            $Bishop --help
            $Bishop -m FlagSetup -sp 0 -a "R R" -s 5000 -o MySamples -v
        
        uses the FlagSetup file (in Bishop's library) to load the map and places an agent in location 0 who took two steps to the right. It then infers the cost and reward function using 5000 samples and stores the output in "MySamples.p"
        
        #### Inside python
        
        	Obs = LoadObserver("Tatik_T1_L1")
        	Res = Obs.InferAgent(['UL'], Samples=100, Feedback=True) #UL (Up-Left) is a diagonal move 
        
        The Observer.InferAgent returns a __PosteriorContainer__ object. Here are some things you can do with it
        
        	Res.Summary()
        	Res.Summary(Human=False) # Or print it in csv-format
        	Res.AnalyzeConvergence() # Visually check if sampling converged
        	Res.PlotCostPosterior()
        	Res.PlotRewardPosterior()
        	Res.Summary(Human=False)
        	SaveSamples(Res, "MyResults")
        
        You can reload the samples and the observer model later with
        
        	Res = LoadSamples("MyResults.p")
        	Obs = LoadObserverFromPC(Res)
        
        ## Creating a new map
        
        ### Through configuration files
        
        A map consists of two files: An ASCII description, and a .ini configuration file.
        
        ASCII files begin with a map drawing, with each terrain type indicated numerically. After a line break, each terrain name is specified in a single line. These are the files for "FlagSetup" map
        
        __FlagSetup.ini__
        
            [MapParameters]
            DiagonalTravel: True
            MapName: Flag_Map
            # Starting point can get overriden later with Observer.SetStartingPoint()
            StartingPoint: 2
            ExitState: 58
            
            [Objects]
            ObjectLocations: 41 49
            ObjectTypes: 0 1
            ObjectNames: LTreat RTreat
            # If the two treats were the same type:
            # ObjectTypes: 0 0
            # ObjectNames: OnlyOneNameNeeded
            
            [AgentParameters]
            # Prior over costs and rewards.
            Prior: ScaledUniform
            # Force terrain 0 to be always less costly than the rest?
            Restrict: False
            SoftmaxChoice = False
            SoftmaxAction = False
            # Softmax parameters
            # actionTau = 0.01
            # choiceTau = 0.01 
            # When different than 0 prior becomes a mixture of the
            # prior above with a peak in 0. The value determines the mass on that point.
            RNull = 0.2
            CNull = 0
            # Parameters for priors. Meaning changes depending on the prior. See docstrings
            CostParameters = 1
            RewardParameters = 10
        
        
        __FlagMap__
        
            0000011122222
            0000011122222
            0000011122222
            0000011122222
            0000011122222
            0000011122222
            0000011122222
            
            LeftTerrainName
            CenterTerrainName
            RightTerrainName
        
        ### Building a map inside python
        
        ##### Map skeleton
        
        To generate a simple grid-world with one terrain start with
        
        	MyMap = Map()
        	MyMap.BuildGridWorld(5,3,Diagonal=True)
        
        This creates a 5 by 3 map that can be navigated diagonally. Terrain type is stored in MyMap.StateTypes. The first terrain has by default a value of 0. New terrains are added through squares:
        
        	MyMap.InsertSquare(2, 1, 2, 3, 1):
        
        added a 2x3 square with the top-left corner positioned on (2,1). Both coordinates begin in 1 and the y-axis is counted from top to bottom. The last argument (1) gives the terrain code. Inserting overlapping squares always rewrites past terrain. You can then add terrain names
        
        	MyMap.AddStateNames(["Water","Jungle"])
        
        To see what your map looks like type
        
        	MyMap.PrintMap()
        
        ##### Adding targets
        
        SOON
        
        ##### Saving the map
        
        SOON
        
        ##### Using the map
        
        Once you have a map, you need to create an agent, and use both to create an observer
        
        	MyAgent = Agent(MyMap, CostParam, RewardParam)
        	MyObserver = Observer(MyMap, MyAgent)
Platform: UNKNOWN
